{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "932afdd9-10e4-4f8a-b26c-418552355aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFlowchart YOLO Project: Cleanup and Reset Notebook\\n\\nThis notebook provides a comprehensive set of utilities to clean up, reset, and prepare your working\\nenvironment for new training and inference runs in the Flowchart-to-Text project. It is designed \\nto streamline disk space management, avoid residual artifacts between runs, and ensure reproducibility.\\n\\nIncluded Cleanup Tasks:\\n-----------------------\\n1. **Remove previous training runs**:\\n   - Deletes all content in `runs/train_test/` (or your YOLO training output directory).\\n   - Ensures stale checkpoints, logs, and visualizations don't interfere with fresh experiments.\\n\\n2. **Clean output visualization folders**:\\n   - Deletes contents from `test_visualizations/`, where test result images are stored.\\n\\n3. **Delete temporary or system files**:\\n   - Removes unwanted `.DS_Store` files and `.ipynb_checkpoints/` folders across the Kaggle dataset directory.\\n   - Helps reduce clutter and potential errors when scanning directories.\\n\\n4. **Clear the full YOLO `runs/` folder**:\\n   - Resets all YOLO experiment outputs, including default `runs/detect`, `runs/train`, and `runs/segment`.\\n\\n5. **Delete all `.pt` YOLO weight files**:\\n   - Removes all YOLO model weight files (`*.pt`) from the current working directory.\\n   - Useful for reclaiming disk space and avoiding loading wrong models.\\n\\n6. **Clear GPU cache (optional but recommended)**:\\n   - Frees up GPU memory using `torch.cuda.empty_cache()` after heavy training or inference.\\n   - Helps mitigate CUDA memory errors in long-running notebooks.\\n\\n7. **Empty the `archive/` directory**:\\n   - Recursively removes all files, symbolic links, and subfolders inside the `archive` directory.\\n   - Preserves the folder itself so it can be reused.\\n   - Useful for managing historical backups or staging data for retraining.\\n\\nUsage Recommendations:\\n----------------------\\n- Run this notebook **before each training cycle** to start clean.\\n- Customize paths as needed depending on your dataset location or output preferences.\\n- Ensure proper permissions when working in shared environments or using mounted storage.\\n\\nDependencies:\\n-------------\\n- Python 3.6+\\n- `os`, `shutil`, `torch` (for GPU memory operations)\\n\\nWarning:\\n--------\\nAll deletion steps are **permanent**. Double-check directory names and file paths before running\\nto avoid accidental data loss.\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Flowchart YOLO Project: Cleanup and Reset Notebook\n",
    "\n",
    "This notebook provides a comprehensive set of utilities to clean up, reset, and prepare your working\n",
    "environment for new training and inference runs in the Flowchart-to-Text project. It is designed \n",
    "to streamline disk space management, avoid residual artifacts between runs, and ensure reproducibility.\n",
    "\n",
    "Included Cleanup Tasks:\n",
    "-----------------------\n",
    "1. **Remove previous training runs**:\n",
    "   - Deletes all content in `runs/train_test/` (or your YOLO training output directory).\n",
    "   - Ensures stale checkpoints, logs, and visualizations don't interfere with fresh experiments.\n",
    "\n",
    "2. **Clean output visualization folders**:\n",
    "   - Deletes contents from `test_visualizations/`, where test result images are stored.\n",
    "\n",
    "3. **Delete temporary or system files**:\n",
    "   - Removes unwanted `.DS_Store` files and `.ipynb_checkpoints/` folders across the Kaggle dataset directory.\n",
    "   - Helps reduce clutter and potential errors when scanning directories.\n",
    "\n",
    "4. **Clear the full YOLO `runs/` folder**:\n",
    "   - Resets all YOLO experiment outputs, including default `runs/detect`, `runs/train`, and `runs/segment`.\n",
    "\n",
    "5. **Delete all `.pt` YOLO weight files**:\n",
    "   - Removes all YOLO model weight files (`*.pt`) from the current working directory.\n",
    "   - Useful for reclaiming disk space and avoiding loading wrong models.\n",
    "\n",
    "6. **Clear GPU cache (optional but recommended)**:\n",
    "   - Frees up GPU memory using `torch.cuda.empty_cache()` after heavy training or inference.\n",
    "   - Helps mitigate CUDA memory errors in long-running notebooks.\n",
    "\n",
    "7. **Empty the `archive/` directory**:\n",
    "   - Recursively removes all files, symbolic links, and subfolders inside the `archive` directory.\n",
    "   - Preserves the folder itself so it can be reused.\n",
    "   - Useful for managing historical backups or staging data for retraining.\n",
    "\n",
    "Usage Recommendations:\n",
    "----------------------\n",
    "- Run this notebook **before each training cycle** to start clean.\n",
    "- Customize paths as needed depending on your dataset location or output preferences.\n",
    "- Ensure proper permissions when working in shared environments or using mounted storage.\n",
    "\n",
    "Dependencies:\n",
    "-------------\n",
    "- Python 3.6+\n",
    "- `os`, `shutil`, `torch` (for GPU memory operations)\n",
    "\n",
    "Warning:\n",
    "--------\n",
    "All deletion steps are **permanent**. Double-check directory names and file paths before running\n",
    "to avoid accidental data loss.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836e141-13b9-43f3-b217-4c0a87dd7626",
   "metadata": {},
   "source": [
    "# Remove previous training runs\n",
    "Ultralytics saves training results under runs/train/ or your custom path like runs/train_test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57daf3a-73d9-4158-a3b8-f64000894c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training runs folder does not exist.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Example: clean up all YOLO training runs\n",
    "train_runs_dir = \"/sfs/ceph/standard/sds_managed_sadewole/DS6050_SP25/group6/kaggle/runs/train_test\"\n",
    "\n",
    "if os.path.exists(train_runs_dir):\n",
    "    shutil.rmtree(train_runs_dir)\n",
    "    print(f\"Removed: {train_runs_dir}\")\n",
    "else:\n",
    "    print(\"Training runs folder does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9a6bc-9ce4-46d5-9ff0-cf1649327d94",
   "metadata": {},
   "source": [
    "# Clean just the output visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97795d1f-78c8-4bc7-b4e9-322ca5de9203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: test_visualizations\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "vis_dir = \"test_visualizations\"\n",
    "\n",
    "if os.path.exists(vis_dir):\n",
    "    shutil.rmtree(vis_dir)\n",
    "    print(f\"Removed: {vis_dir}\")\n",
    "else:\n",
    "    print(\"Visualization folder not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e9ac0-dad9-4770-83f7-1d2f8cd4672a",
   "metadata": {},
   "source": [
    "# Delete .DS_Store, .ipynb_checkpoints, or other temp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "876c3b04-0120-436d-a522-bc5d90a6a2f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp files removed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def delete_temp_files(root_dir):\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file in [\".DS_Store\"]:\n",
    "                os.remove(os.path.join(root, file))\n",
    "        for d in dirs:\n",
    "            if d == \".ipynb_checkpoints\":\n",
    "                shutil.rmtree(os.path.join(root, d), ignore_errors=True)\n",
    "\n",
    "# Run on your Kaggle dataset folder\n",
    "delete_temp_files(\"/sfs/ceph/standard/sds_managed_sadewole/DS6050_SP25/group6/kaggle\")\n",
    "print(\"Temp files removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946dfb7-27c1-49a4-ac24-154b97ea5835",
   "metadata": {},
   "source": [
    "# Reset the YOLO runs/ folder entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d020698-4b0b-456e-b524-7a9fffa7c943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All YOLO runs cleared.\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(\"/sfs/ceph/standard/sds_managed_sadewole/DS6050_SP25/group6/kaggle/runs\", ignore_errors=True)\n",
    "print(\"All YOLO runs cleared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f669a3-c9ed-42b4-ac9b-5b3678bc581b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Delete all Yolo weight (.pt) files in the current diretory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b178ccb-42ce-4f10-b5f2-16234e4bb391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: yolov9s.pt\n",
      "Deleted: yolo11n.pt\n"
     ]
    }
   ],
   "source": [
    "#  Delete all YOLO weight (.pt) files in the current directory\n",
    "\n",
    "import os\n",
    "\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.endswith(\".pt\"):\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316018f5-aaac-4563-b6f3-2e14c71fda0a",
   "metadata": {},
   "source": [
    "# Clear out GPU Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e913a491-ac06-4949-a5f6-61ace1b851d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Clear GPU cache (optional but helpful after training or large inference runs) ===\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU cache cleared.\")\n",
    "else:\n",
    "    print(\"No GPU available to clear.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c91d17-cf74-412a-bbbb-cea8892c55bc",
   "metadata": {},
   "source": [
    "# Clean Out Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69626906-2ac1-46d8-ae38-6bf1e6280be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "archive_dir = \"/sfs/ceph/standard/sds_managed_sadewole/DS6050_SP25/group6/kaggle/archive\"\n",
    "\n",
    "if os.path.exists(archive_dir):\n",
    "    for filename in os.listdir(archive_dir):\n",
    "        file_path = os.path.join(archive_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove file or symlink\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove directory and contents\n",
    "            print(f\"Removed: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(\"Archive directory does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89747204-74b7-49d7-9178-441591b1a328",
   "metadata": {},
   "source": [
    "# Clean up the processing_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29c6ad20-7b69-4502-8189-e71b1d859716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing_log.txt has been deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "log_file_path = 'processing_log.txt'\n",
    "\n",
    "# Check if the file exists and delete it\n",
    "if os.path.exists(log_file_path):\n",
    "    os.remove(log_file_path)\n",
    "    print(f\"{log_file_path} has been deleted.\")\n",
    "else:\n",
    "    print(f\"{log_file_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99be83-a022-45c5-9f52-6766bf8075b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
